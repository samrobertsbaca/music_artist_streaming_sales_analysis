---
title: "Music Streaming & Sales Analysis"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(ggpubr)
library(boot)
library(ggrepel)
library(psych)
library(dplyr)
```

```{r}

# Reading in / parsing data

# Basic song info dataset
dat <- read.csv("JKC_Data.csv",stringsAsFactors = FALSE, fileEncoding="UTF-8-BOM",
                sep=",",header = TRUE)

# Remove unnecessary Instruments/Genres columns
drops <- c("Instruments","Genres")
dat <- dat[ , !(names(dat) %in% drops)]

# Turn blanks/empty spaces into NA
#dat[dat==""]<-NA


# Streams / Sales dataset
sales_dat <- read.csv("DistroKid_JohnKingCave.csv",stringsAsFactors = FALSE, fileEncoding="UTF-8-BOM",
                sep=",",header = TRUE)
# Turn blanks/empty spaces into NA
sales_dat[sales_dat==""]<-NA

# Drop unnecessary sales_dat columns
drops <- c("Reporting.Date","Aritst","Title","Song.Album")
sales_dat <- sales_dat[ , !(names(sales_dat) %in% drops)]

# Merge the "Sales" and "Info" datasets by "ISRC" variable
dat.all <- merge(dat,sales_dat,by="ISRC")

# 30 songs were originally used in our input, however 4 were dropped. "Emotion", "Tread Light", and "2062 CE" were dropped since they were not released on DistroKid. "Just for a Moment" was dropped since there was no sales/streaming data available from DistroKid at the time the sales data was downloaded.

```

```{r}

# Looking at Total number of streams/sales by Song

dat.song_summary <- dat.all %>% group_by(ISRC, Song.Title, Store) %>%
    summarize(Quantity = sum(Quantity),
              Earnings.USD = sum(Earnings.USD))

dat.song_summary_totals <- dat.song_summary %>% group_by(ISRC, Song.Title) %>%
    summarize(TotalQuantity = sum(Quantity),
              TotalEarnings.USD = sum(Earnings.USD))
dat.song_summary_totals_titles <- dat.song_summary_totals

drops <- c("Song.Title")
dat.song_summary_totals <- dat.song_summary_totals[ , !(names(dat.song_summary_totals) %in% drops)]

dat.song_summary <- merge(dat.song_summary,dat.song_summary_totals,by="ISRC")
dat.song_summary <- unique( dat.song_summary )


g1 <- ggplot(dat.song_summary,aes(x= reorder(Song.Title,-TotalQuantity),Quantity, fill=Store))+geom_bar(position="stack", stat="identity") + theme(axis.text.x = element_text(angle = 30, hjust = 1, size=6)) + xlab("Song") + ylab("Number of Streams") + ggtitle("Total Number of Streams by Song")
g1

g2 <- ggplot(dat.song_summary,aes(x= reorder(Song.Title,-TotalEarnings.USD),Earnings.USD, fill=Store))+geom_bar(position="stack", stat="identity") + theme(axis.text.x = element_text(angle = 30, hjust = 1, size=6)) + xlab("Song") + ylab("Total Earnings (USD)") + ggtitle("Total Number of Sales by Song")
g2


g3 <- ggplot(dat.song_summary,aes(x= TotalQuantity,y = TotalEarnings.USD))+geom_point() + theme(axis.text.x = element_text(angle = 30, hjust = 1)) + xlab("Number of Streams") + ylab("Total Earnings (USD)") + ggtitle("Total Earnings by Total Streams for each Song Best Fit Line")

linear_fit <- lm(TotalEarnings.USD~TotalQuantity,data=dat.song_summary)
summary(linear_fit)

g3 <- g3 + stat_smooth(method = "lm", formula = y ~ x)
g3

# According to our linear fit examining earnings over streams, for each stream there is an increase in approximately .003 US dollars. Therefore, hypothetically, if one wanted to make a million dollars from streams, we would have to have at least 333 million streams. Our R^2 = .773 and p-value is 7.005e-08, so we are fairly certain there is a strong correlation between streams and sales.

# But how does this break down according by streaming platform?

g4 <- ggplot(dat.song_summary,aes(x= TotalQuantity,y = TotalEarnings.USD, fill=Store, color=Store))+geom_point() + theme(axis.text.x = element_text(angle = 30, hjust = 1)) + xlab("Number of Streams") + ylab("Total Earnings (USD)") + ggtitle("Total Earnings by Total Streams for each Song Best Fit Line by Store")

linear_fit <- lm(Earnings.USD~Quantity,data=dat.song_summary)
summary(linear_fit)

g4 <- g4 + stat_smooth(method = "lm", formula = y ~ x)
g4

```


```{r}

# Looking at Total numbers of Streams/Sales by Platform

store_count <- aggregate(cbind(Quantity = dat.all$Quantity,Earnings.USD = dat.all$Earnings.USD), by=list(Store=dat.all$Store), FUN=sum)

g1 <- ggplot(store_count,aes(x= reorder(Store,-Quantity),Quantity))+geom_bar(stat ="identity") + theme(axis.text.x = element_text(angle = 30, hjust = 1)) + xlab("Store") + ylab("Number of Streams") + ggtitle("Total Number of Streams by Platform")

g2 <- ggplot(store_count,aes(x= reorder(Store,-Earnings.USD),Earnings.USD))+geom_bar(stat ="identity") + theme(axis.text.x = element_text(angle = 30, hjust = 1)) + xlab("Store") + ylab("Total Earnings (USD)") + ggtitle("Total Number of Sales by Platform")

g1
g2

g3 <- ggplot(store_count,aes(x= Quantity,y = Earnings.USD))+geom_point() + theme(axis.text.x = element_text(angle = 30, hjust = 1)) + xlab("Number of Streams") + ylab("Total Earnings (USD)") + ggtitle("Total Earnings by Total Streams for each Platform") + geom_label_repel(aes(label = Store),
                  box.padding   = 0.35, 
                  point.padding = 0.5,
                  segment.color = 'grey50',
                  max.overlaps = 14,
                  alpha = .5)
g3

# As we can see, the top two platforms for streams in the given reporting period are Spotify and Apple Music. The top three platforms for sales in the given reporting period are Spotify, iTunes, and Apple Music. All other services are clear outliers in terms of sales and streams.

# Interestingly enough, iTunes is the clear exception when it comes to earnings per streams. This may be attributed to the fact that songs can be purchased directly from iTunes instead of streamed for free (for the user).

dat.no_outliers <- filter(dat.all, !(Store %in% c("youtube", "amazon unlimited", "youtube red", "deezer", "itunesmatch", "kkbox", "google play all access")))
dat.no_outliers <- dat.no_outliers %>%
  arrange(desc(Store))

```
```{r}

# Principal Component Analysis

dat.cat <- dat.song_summary_totals_titles[, c("ISRC", "TotalQuantity", "TotalEarnings.USD")]
dat.cat <- unique( dat.cat )

dat.cat <- merge(dat.cat,dat,by="ISRC")

# Drop unnecessary sales_dat columns
drops <- c("ISRC", "Album.Title","Track","Lyrics","Release.Date","Instruments", "Genres", "Sale.Month","Artist", "Duration", "Vocals", "Store", "Country.of.Sale", "Quantity", "Earnings.USD")
dat.cat <- dat.cat[ , !(names(dat.cat) %in% drops)]
dat.cat$rownames = dat.cat$Song.Title

rownames(dat.cat) <- dat.cat$Song.Title

drops <- c("Song.Title")
dat.cat <- dat.cat[ , !(names(dat.cat) %in% drops)]

dat.cat <- within(dat.cat, rm("rownames"))

library(factoextra)
dat.pca <- prcomp(dat.cat[3:33], scale = TRUE)
fviz_eig(dat.pca)

summary(dat.pca)

fviz_pca_ind(dat.pca,
             col.ind = "cos2", # Color by the quality of representation
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )

fviz_pca_var(dat.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )

fviz_pca_biplot(dat.pca, repel = TRUE,
                col.var = "#2E9FDF", # Variables color
                col.ind = "#696969"  # Individuals color
                )

# Predict coordinates and compute cos2
quanti.coord <- cor(dat.cat[1:2], dat.pca$x)
quanti.cos2 <- quanti.coord^2
# Graph of variables including supplementary variables
p <- fviz_pca_var(dat.pca,col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), max.overlaps = 15, repel = TRUE)
fviz_add(p, quanti.coord, color ="blue", geom="arrow")

# Eigenvalues
eig.val <- get_eigenvalue(dat.pca)
eig.val
  
# Results for Variables
res.var <- get_pca_var(dat.pca)
res.var$coord          # Coordinates
res.var$contrib        # Contributions to the PCs
res.var$cos2           # Quality of representation 
# Results for individuals
res.ind <- get_pca_ind(dat.pca)
res.ind$coord          # Coordinates
res.ind$contrib        # Contributions to the PCs
res.ind$cos2           # Quality of representation 

#names(dat.cat)                        #what are the variables?
#describe(dat.cat)                     #basic summary statistics -- check for miscodings


# Let's see if we obtain similar results with Factor Analysis.
# Factor Analysis

dat.cat <- na.omit(dat.cat)     #remove the cases with missing values
f2 <- fa(dat.cat,2,rotation="varimax")   		#factor analyze the resulting item
#(f2)                                              #show the result
load=loadings(f2)
print(load,sort=TRUE,digits=2,cutoff=0.01)  #show the loadings       
#plot(load)                                 #plot factor 1 by 2
#identify(load,labels=names(dat.cat))           
 	#put names of selected points onto the figure  -- to stop, click with command key
 plot(f2,labels=names(dat.cat), cex=0.75)
  #ggplot(f2)

 
 
```

```{r}

# Bootstrap t-test function from https://rdrr.io/cran/MKinfer/src/R/boot.t.test.R

boot.t.test <- function(x, ...){ 
  UseMethod("boot.t.test")
}
boot.t.test.default <- function(x, y = NULL, alternative = c("two.sided", "less", "greater"), 
                        mu = 0, paired = FALSE, var.equal = FALSE, 
                        conf.level = 0.95, R = 9999, symmetric = FALSE, ...){
  alternative <- match.arg(alternative)
  if(!missing(mu) && (length(mu) != 1 || is.na(mu))) 
    stop("'mu' must be a single number")
  if(!missing(conf.level) && (length(conf.level) != 1 || !is.finite(conf.level) || 
                               conf.level < 0 || conf.level > 1)) 
    stop("'conf.level' must be a single number between 0 and 1")
  if(!is.null(y)){
    dname <- paste(deparse(substitute(x)), "and", deparse(substitute(y)))
    if (paired) 
      xok <- yok <- complete.cases(x, y)
    else{
      yok <- !is.na(y)
      xok <- !is.na(x)
    }
    y <- y[yok]
  }else{
    dname <- deparse(substitute(x))
    if (paired) 
      stop("'y' is missing for paired test")
    xok <- !is.na(x)
    yok <- NULL
  }
  x <- x[xok]
  if(paired){
    x <- x - y
    y <- NULL
  }
  nx <- length(x)
  mx <- mean(x)
  vx <- var(x)
  if (is.null(y)) {
    if (nx < 2) 
      stop("not enough 'x' observations")
    df <- nx - 1
    stderr <- sqrt(vx/nx)
    if (stderr < 10 * .Machine$double.eps * abs(mx)) 
      stop("data are essentially constant")
    tstat <- (mx - mu)/stderr
    method <- if (paired) "Bootstrapped Paired t-test" else "Bootstrapped One Sample t-test"
    estimate <- setNames(mx, if (paired) "mean of the differences" else "mean of x")
    x.cent <- x - mx
    X <- matrix(sample(x.cent, size = nx*R, replace = TRUE), nrow = R)
    MX <- rowMeans(X)
    VX <- rowSums((X-MX)^2)/(nx-1)
    STDERR <- sqrt(VX/nx)
    TSTAT <- MX/STDERR
    EFF <- MX+mx
  }else{
    ny <- length(y)
    if(nx < 1 || (!var.equal && nx < 2)) 
      stop("not enough 'x' observations")
    if(ny < 1 || (!var.equal && ny < 2)) 
      stop("not enough 'y' observations")
    if(var.equal && nx + ny < 3) 
      stop("not enough observations")
    my <- mean(y)
    vy <- var(y)
    method <- paste("Bootstrapped", paste(if (!var.equal) "Welch", "Two Sample t-test"))
    estimate <- c(mx, my)
    names(estimate) <- c("mean of x", "mean of y")
    if(var.equal){
      df <- nx + ny - 2
      v <- 0
      if (nx > 1) 
        v <- v + (nx - 1) * vx
      if (ny > 1) 
        v <- v + (ny - 1) * vy
      v <- v/df
      stderr <- sqrt(v * (1/nx + 1/ny))
      z <- c(x, y)
      Z <- matrix(sample(z, size = (nx+ny)*R, replace = TRUE), nrow = R)
      X <- Z[,1:nx]
      Y <- Z[,(nx+1):(nx+ny)]
      MX <- rowMeans(X)
      MY <- rowMeans(Y)
      V <- (rowSums((X-MX)^2) + rowSums((Y-MY)^2))/df
      STDERR <- sqrt(V*(1/nx + 1/ny))
      EFF <- (MX+mx) - (MY+my)
    }else{
      stderrx <- sqrt(vx/nx)
      stderry <- sqrt(vy/ny)
      stderr <- sqrt(stderrx^2 + stderry^2)
      df <- stderr^4/(stderrx^4/(nx - 1) + stderry^4/(ny - 1))
      z <- c(x, y)
      mz <- mean(z)
      x.cent <- x - mx + mz
      y.cent <- y - my + mz
      X <- matrix(sample(x.cent, size = nx*R, replace = TRUE), nrow = R)
      Y <- matrix(sample(y.cent, size = ny*R, replace = TRUE), nrow = R)
      MX <- rowMeans(X)
      MY <- rowMeans(Y)
      VX <- rowSums((X-MX)^2)/(nx-1)
      VY <- rowSums((Y-MY)^2)/(ny-1)
      STDERR <- sqrt(VX/nx + VY/ny)
      EFF <- (MX+mx) - (MY+my)
    }
    if (stderr < 10 * .Machine$double.eps * max(abs(mx), abs(my))) 
      stop("data are essentially constant")
    tstat <- (mx - my - mu)/stderr
    TSTAT <- (MX - MY)/STDERR
  }
  if (alternative == "less") {
    pval <- pt(tstat, df)
    boot.pval <- mean(TSTAT < tstat)
    cint <- c(-Inf, tstat + qt(conf.level, df))
    boot.cint <- c(-Inf, quantile(EFF, conf.level))
  }else if(alternative == "greater") {
    boot.pval <- mean(TSTAT > tstat)
    pval <- pt(tstat, df, lower.tail = FALSE)
    cint <- c(tstat - qt(conf.level, df), Inf)
    boot.cint <- c(quantile(EFF, 1-conf.level), Inf)
  }else{
    pval <- 2 * pt(-abs(tstat), df)
    if(symmetric)
      boot.pval <- mean(abs(TSTAT) > abs(tstat))
    else
      boot.pval <- 2*min(mean(TSTAT <= tstat), mean(TSTAT > tstat))
    alpha <- 1 - conf.level
    cint <- qt(1 - alpha/2, df)
    cint <- tstat + c(-cint, cint)
    boot.cint <- quantile(EFF, c(alpha/2, 1-alpha/2))
  }
  cint <- mu + cint * stderr
  names(tstat) <- "t"
  names(df) <- "df"
  names(mu) <- if (paired || !is.null(y)) "difference in means" else "mean"
  attr(cint, "conf.level") <- conf.level
  attr(boot.cint, "conf.level") <- conf.level
  rval <- list(statistic = tstat, parameter = df, p.value = pval, 
               boot.p.value = boot.pval,
               conf.int = cint, boot.conf.int = boot.cint,
               estimate = estimate, null.value = mu, 
               stderr = stderr, alternative = alternative, method = method, 
               data.name = dname)
  class(rval) <- c("boot.htest", "htest")
  rval
}
boot.t.test.formula <- function (formula, data, subset, na.action, ...){
  if (missing(formula) || (length(formula) != 3L) || (length(attr(terms(formula[-2L]), 
                                                                  "term.labels")) != 1L)) 
    stop("'formula' missing or incorrect")
  m <- match.call(expand.dots = FALSE)
  if (is.matrix(eval(m$data, parent.frame()))) 
    m$data <- as.data.frame(data)
  m[[1L]] <- quote(stats::model.frame)
  m$... <- NULL
  mf <- eval(m, parent.frame())
  DNAME <- paste(names(mf), collapse = " by ")
  names(mf) <- NULL
  response <- attr(attr(mf, "terms"), "response")
  g <- factor(mf[[-response]])
  if (nlevels(g) != 2L) 
    stop("grouping factor must have exactly 2 levels")
  DATA <- setNames(split(mf[[response]], g), c("x", "y"))
  y <- do.call("boot.t.test", c(DATA, list(...)))
  y$data.name <- DNAME
  if (length(y$estimate) == 2L) 
    names(y$estimate) <- paste("mean in group", levels(g))
  y
}
print.boot.htest <- function (x, digits = getOption("digits"), prefix = "\t", ...) {
  cat("\n")
  cat(strwrap(x$method, prefix = prefix), sep = "\n")
  cat("\n")
  cat("data:  ", x$data.name, "\n", sep = "")
  out <- character()
  if (!is.null(x$boot.p.value)) {
    bfp <- format.pval(x$boot.p.value, digits = max(1L, digits - 3L))
    cat("bootstrapped p-value", 
        if (substr(bfp, 1L, 1L) == "<") bfp else paste("=", bfp), "\n")
  }
  if (!is.null(x$conf.int)) {
    cat(format(100 * attr(x$boot.conf.int, "conf.level")), 
        " percent bootstrap percentile confidence interval:\n", 
        " ", paste(format(x$boot.conf.int[1:2], digits = digits), 
                   collapse = " "), "\n", sep = "")
  }
  cat("\nResults without bootstrap:\n")
  if (!is.null(x$statistic)) 
    out <- c(out, paste(names(x$statistic), "=", format(x$statistic, 
                                                        digits = max(1L, digits - 2L))))
  if (!is.null(x$parameter)) 
    out <- c(out, paste(names(x$parameter), "=", format(x$parameter, 
                                                        digits = max(1L, digits - 2L))))
  if (!is.null(x$p.value)) {
    fp <- format.pval(x$p.value, digits = max(1L, digits - 
                                                3L))
    out <- c(out, paste("p-value", 
                        if (substr(fp, 1L, 1L) == "<") fp else paste("=", fp)))
  }
  cat(strwrap(paste(out, collapse = ", ")), sep = "\n")
  if (!is.null(x$alternative)) {
    cat("alternative hypothesis: ")
    if (!is.null(x$null.value)) {
      if (length(x$null.value) == 1L) {
        alt.char <- switch(x$alternative, two.sided = "not equal to", 
                           less = "less than", greater = "greater than")
        cat("true ", names(x$null.value), " is ", alt.char, 
            " ", x$null.value, "\n", sep = "")
      }
      else {
        cat(x$alternative, "\nnull values:\n", sep = "")
        print(x$null.value, digits = digits, ...)
      }
    }
    else cat(x$alternative, "\n", sep = "")
  }
  if (!is.null(x$conf.int)) {
    cat(format(100 * attr(x$conf.int, "conf.level")), " percent confidence interval:\n", 
        " ", paste(format(x$conf.int[1:2], digits = digits), 
                   collapse = " "), "\n", sep = "")
  }
  if (!is.null(x$estimate)) {
    cat("sample estimates:\n")
    print(x$estimate, digits = digits, ...)
  }
  cat("\n")
  invisible(x)
}
```

```{r}

synthesizer_songs <- dat.cat[which(dat.cat$Synthesizer == 1), ,]
synthesizer.quantity <- synthesizer_songs$TotalQuantity
synthesizer.earnings <- synthesizer_songs$TotalEarnings.USD

mu_TotalQuantity <- mean(dat.cat$TotalQuantity)
mu_TotalEarnings.USD <- mean(dat.cat$TotalEarnings.USD)

ggqqplot(dat.cat$TotalQuantity,title="All Songs Total Number of Streams Distribution Q-Q Plot")
ggqqplot(dat.cat$TotalEarnings.USD,title="All Songs Total Earnings Distribution Q-Q Plot")
ggqqplot(synthesizer_songs$TotalQuantity,title="Songs with Synthesizer Total Number of Streams Distribution Q-Q Plot")
ggqqplot(synthesizer_songs$TotalEarnings.USD,title="Songs with Synthesizer Total Earnings Distribution Q-Q Plot")

ggplot(data=dat.cat,aes(x=TotalQuantity)) + geom_histogram(bins=33) + ggtitle("All Songs Total Number of Streams Distribution")
ggplot(data=dat.cat,aes(x=TotalEarnings.USD)) + geom_histogram(bins=33) + ggtitle("All Songs Total Earnings Distribution")
ggplot(data=synthesizer_songs,aes(x=TotalQuantity)) + geom_histogram(bins=33) + ggtitle("Songs with Synthesizer Total Number of Streams Distribution")
ggplot(data=synthesizer_songs,aes(x=TotalEarnings.USD)) + geom_histogram(bins=33) + ggtitle("Songs with Synthesizer Total Earnings Distribution")

# Null Hypothesis 1: The average total number of streams for songs with a synthesizer are equal to the average total number of streams for songs without a synthesizer.
# Alternative Hypothesis 1: The average total number of streams for songs with a synthesizer is greater than the average total number of streams for songs without a synthesizer.

# Null Hypothesis 2: The average total number of earnings for songs with a synthesizer are equal to the average total number of earnings for songs without a synthesizer.
# Alternative Hypothesis 2: The average total number of earnings for songs with a synthesizer are greater than the average total number of earnings for songs without a synthesizer.

t.test(synthesizer_songs$TotalQuantity, mu = mu_TotalQuantity, alternative = "greater")
t.test(synthesizer_songs$TotalEarnings.USD, mu = mu_TotalEarnings.USD, alternative = "greater")

boot.test1 <- boot.t.test(x = synthesizer_songs$TotalQuantity, y = NULL,
       alternative = "greater",
       mu = mu_TotalQuantity, paired = FALSE, var.equal = FALSE,
       conf.level = 0.95, R = 1000)

boot.test2 <- boot.t.test(x = synthesizer_songs$TotalEarnings.USD, y = NULL,
       alternative = "greater",
       mu = mu_TotalEarnings.USD, paired = FALSE, var.equal = FALSE,
       conf.level = 0.95, R = 1000)

boot.test1
boot.test2

ggplot(data=dat.cat,aes(x=TotalQuantity)) + geom_histogram(bins=33) + ggtitle("All Songs Total Number of Streams Distribution with Bootstrap Synthesizer Estimate") + geom_vline(xintercept = boot.test1$estimate, col="red")
ggplot(data=dat.cat,aes(x=TotalEarnings.USD)) + geom_histogram(bins=33) + ggtitle("All Songs Total Earnings Distribution With Bootstrap Synthesizer Estimate") + geom_vline(xintercept = boot.test2$estimate, col="red")

boot.test1$estimate[1]
boot.test2$estimate[1]

```

```{r}

# Classical MDS
# N rows (objects) x p columns (variables)
# each row identified by a unique row name

d <- dist(dat.cat) # euclidean distances between the rows
fit <- cmdscale(d,eig=TRUE, k=2) # k is the number of dim
fit # view results

# plot solution
x <- fit$points[,1]
y <- fit$points[,2]
plot(x, y, xlab="Coordinate 1", ylab="Coordinate 2",
  main="Metric MDS", type="n")
text(x, y, labels = row.names(dat.cat), cex=.7) 


# Nonmetric MDS
# N rows (objects) x p columns (variables)
# each row identified by a unique row name

library(MASS)
d <- dist(dat.cat) # euclidean distances between the rows
fit <- isoMDS(d, k=2) # k is the number of dim
fit # view results

# plot solution
x <- fit$points[,1]
y <- fit$points[,2]
plot(x, y, xlab="Coordinate 1", ylab="Coordinate 2",
  main="Nonmetric MDS", type="n")
text(x, y, labels = row.names(dat.cat), cex=.7) 

```